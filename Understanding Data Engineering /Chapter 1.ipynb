{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hb-7ZgoIeevY",
        "llzO5ut6fZSj",
        "1_o6rgzYgSP_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 1"
      ],
      "metadata": {
        "id": "mdz21L2jbr96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data WorkFlow\n",
        "\n",
        "  `Data Collection & Storage`--> `Data preparation`-->`Exploration & Visualization`-->`Experimentation & Prediction`\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "xU-Cbn1PcC97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Engineers** are in charge of the first step of the workflow. If data is too scattered and can't be used then there's no way for  the data analysts , data scientist to do their job!"
      ],
      "metadata": {
        "id": "jc2YPnM7dN2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data engineers deliver\n"
      ],
      "metadata": {
        "id": "hb-7ZgoIeevY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The correct data.\n",
        "\n",
        "* In the right form.\n",
        "\n",
        "* to the right people."
      ],
      "metadata": {
        "id": "7rSiZ79RfVeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A data engineer's responsibilities"
      ],
      "metadata": {
        "id": "llzO5ut6fZSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ingest data from different sources\n",
        "\n",
        "* Optimize databases for analysis\n",
        "\n",
        "* Remove corrupted data\n",
        "\n",
        "* Develop, construct, test and maintain data architectures"
      ],
      "metadata": {
        "id": "Az8pOc3Ufq7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data engineers and big data\n"
      ],
      "metadata": {
        "id": "1_o6rgzYgSP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Big data becomes the norm => data engineers are more and more needed\n",
        "\n",
        "* Big data:\n",
        "  * Have to think about how to deal with its size\n",
        "\n",
        "  * So large traditional methods don't work anymore"
      ],
      "metadata": {
        "id": "kFooUJivgW_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Five Vs"
      ],
      "metadata": {
        "id": "Rse1KvqYhz20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Volume (How much data?)\n",
        "\n",
        "* Variety (What kind of data?)\n",
        "\n",
        "* Velocity (How frequentn is the data coming?)\n",
        "\n",
        "* Veracity (How accurate is this data?)\n",
        "\n",
        "* Value (how useful is the data?)"
      ],
      "metadata": {
        "id": "O7lfBfn4h3hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xinHRzSrj4Xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data engineers vs Data scientists"
      ],
      "metadata": {
        "id": "EQMOQFC5j7eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data engineer's role:\n",
        "Their role is to ingest and store the data so its easily accesible and ready to be analyzed\n",
        "\n",
        "### Data scientist's role:\n",
        "\n",
        "They intervene on the rest of the workflow: they prepare the data according to their analysis needs, explore it, build insightful visualizations, and then run experiments or build predictive models\n",
        "\n",
        "*`data Engineers lay the groundwork that makes data science's activity possible`*\n"
      ],
      "metadata": {
        "id": "sLetpJlIj_x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How do they do it?\n"
      ],
      "metadata": {
        "id": "6XbnGcMplfNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see some differences"
      ],
      "metadata": {
        "id": "l0fztFhloLMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|     |     | |\n",
        "|---|---|---|\n",
        "|Data Engineer| Data Scientist|\n",
        "|Ingest and store data| Exploit data|\n",
        "|Set up databases| Access Databases|\n",
        "|Build data pipelines| Use pipeline outputs|\n",
        "|Strong software Skills | Strong analytical skills|\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qhi6n7Ezljap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Data pipeline"
      ],
      "metadata": {
        "id": "Vv5KhyQ3oTz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*` if data is the new oil....`*"
      ],
      "metadata": {
        "id": "84_7AlImom_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* some of the oil turns into kerosene and it's sent to airports to fuel airplanes\n",
        "* some oil is refined all the way up until it becomes gasoline for cars\n",
        "\n",
        "* some manufacturers use synthetic polymers to create products , like CDs\n",
        "\n",
        "**And for this processes to be possible there's a need for pipelines**"
      ],
      "metadata": {
        "id": "9YyEbKCYo358"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Back to data engineering\n",
        "\n",
        "`Ingest` -> `Process` -> `Store`-> `Need pipelines`-> `Automate flow from one station to the next` -> `Provide up-to-date, accurate , relevant data`"
      ],
      "metadata": {
        "id": "C6YISdT_qLil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data pipelines ensure an efficient flow of the data\n",
        "\n",
        "|   |    |   |\n",
        "|---|----|---|\n",
        "|Automate|Reduce|\n",
        "|Extracting| Human Intervention\n",
        "|Transforming| Errors|\n",
        "|Combining |Time it takes data to flow |\n",
        "|Validating | |\n",
        "|Loading| |\n",
        "\n"
      ],
      "metadata": {
        "id": "7woTEvvhrfPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ETL and data pipelines\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "|ETL|Data pipelines|\n",
        "|Popular framework for designing data pipelines| Move data from one system to another |\n",
        "|1.Extract data| May follow ETL|\n",
        "|2. Transform extracted data| Data may not be transformed|\n",
        "|3. Load transformed data to another database| Data may be directly loaded in applications|"
      ],
      "metadata": {
        "id": "WC109BO3tDe3"
      }
    }
  ]
}